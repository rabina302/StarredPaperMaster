{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract features using MetaMap\n",
    "# from pymetamap import MetaMap\n",
    "# mm = MetaMap.get_instance('/Users/rabinakhatiwada/Documents/pymetamap-master/public_mm/bin/metamap16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sents = ['Sleep Apnea Obstructive']\n",
    "# concepts,error = mm.extract_concepts(sents,[1,2])\n",
    "# for concept in concepts:\n",
    "#     types = concept.semtypes.strip(\"[]\").split(\",\") # Returns an iterable list of all semtypes\n",
    "#     for type in types:\n",
    "#         print(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Mrs. Jones came in today complaining of a lot of chest pain. She denies shortness of breath and fevers.\"\n",
    "# concepts, error = mm.extract_concepts([text])\n",
    "# for concept in concepts:\n",
    "#     print(concept)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN DATASET\n",
    "data = pd.read_csv('data.csv')\n",
    "data = data.dropna(subset=['text', 'label']) # Remove all rows with missing values\n",
    "data['text'] = data['text'].str.replace(r'[^\\w\\s]+', '', regex=True) # Remove all punctuation\n",
    "data['text'] = data['text'].str.encode('ascii', 'ignore').str.decode('ascii') # Remove all non-ASCII chars\n",
    "data['index'] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare entity types as a list\n",
    "entity_types = [\n",
    "    'aapp', 'acab', 'acty', 'aggp', 'amas', 'amph', 'anab', 'anim', 'anst', 'antb',\n",
    "    'arch', 'bacs', 'bact', 'bdsu', 'bdsy', 'bhvr', 'biof', 'bird', 'blor', 'bmod',\n",
    "    'bodm', 'bpoc', 'bsoj', 'celc', 'celf', 'cell', 'cgab', 'chem', 'chvf', 'chvs',\n",
    "    'clas', 'clna', 'clnd', 'cnce', 'comd', 'crbs', 'diap', 'dora', 'drdd', 'dsyn',\n",
    "    'edac', 'eehu', 'elii', 'emod', 'emst', 'enty', 'enzy', 'euka', 'evnt', 'famg',\n",
    "    'ffas', 'fish', 'fndg', 'fngs', 'food', 'ftcn', 'genf', 'geoa', 'gngm', 'gora',\n",
    "    'grpa', 'grup', 'hcpp', 'hcro', 'hlcs', 'hops', 'horm', 'humn', 'idcn', 'imft',\n",
    "    'inbe', 'inch', 'inpo', 'inpr', 'irda', 'lang', 'lbpr', 'lbtr', 'mamm', 'mbrt',\n",
    "    'mcha', 'medd', 'menp', 'mnob', 'mobd', 'moft', 'mosq', 'neop', 'nnon', 'npop',\n",
    "    'nusq', 'ocac', 'ocdi', 'orch', 'orga', 'orgf', 'orgm', 'orgt', 'ortf', 'patf',\n",
    "    'phob', 'phpr', 'phsf', 'phsu', 'plnt', 'podg', 'popg', 'prog', 'pros', 'qlco',\n",
    "    'qnco', 'rcpt', 'rept', 'resa', 'resd', 'rnlw', 'sbst', 'shro', 'socb', 'sosy',\n",
    "    'spco', 'tisu', 'tmco', 'topp', 'virs', 'vita', 'vtbt'\n",
    "    ]\n",
    "    \n",
    "# Set entity types to 0 in the DataFrame\n",
    "data[entity_types] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into chunks to avoid resource errors\n",
    "# chunk_size = 90\n",
    "# chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract MetaMap concepts\n",
    "def extract_mm_concepts(row):\n",
    "    concepts_list = []\n",
    "\n",
    "    sents = [row['text']]\n",
    "\n",
    "    try:\n",
    "        concepts, error = mm.extract_concepts(\n",
    "            sents,\n",
    "            [1],\n",
    "            word_sense_disambiguation=True,\n",
    "            ignore_stop_phrases=True,\n",
    "            composite_phrase=0,\n",
    "            prune=20\n",
    "        )\n",
    "\n",
    "        concepts_list.extend(concepts)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting concepts: {e}\")\n",
    "\n",
    "    return concepts_list\n",
    "\n",
    "# Update the entity type counts for each row\n",
    "for index, row in data.iterrows():\n",
    "    concepts = extract_mm_concepts(row)\n",
    "\n",
    "    for concept in concepts:\n",
    "        types = concept.semtypes.strip(\"[]\").split(\",\")\n",
    "        for type in types:\n",
    "            if type in entity_types:\n",
    "                data.at[index, type] += 1\n",
    "\n",
    "# Print the updated data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataframe to a new file\n",
    "data.to_csv('_most_recent_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = data.drop(['title','text','source','index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.to_csv(\"metamap_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
